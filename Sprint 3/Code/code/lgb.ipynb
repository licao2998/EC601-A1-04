{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce8899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458913, 2291)\n",
      "(924621, 2290)\n",
      "Start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 95062, number of negative: 272068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.552827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330653\n",
      "[LightGBM] [Info] Number of data points in the train set: 367130, number of used features: 2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051523\n",
      "[LightGBM] [Info] Start training from score -1.051523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\lightgbm\\callback.py:223: UserWarning: Early stopping is not available in dart mode\n",
      "  _log_warning('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttraining's binary_logloss: 0.514737\ttraining's amex_metric: 0.763407\tvalid_1's binary_logloss: 0.51504\tvalid_1's amex_metric: 0.759869\n",
      "[100]\ttraining's binary_logloss: 0.495068\ttraining's amex_metric: 0.766649\tvalid_1's binary_logloss: 0.49548\tvalid_1's amex_metric: 0.763829\n",
      "[150]\ttraining's binary_logloss: 0.485636\ttraining's amex_metric: 0.768048\tvalid_1's binary_logloss: 0.486132\tvalid_1's amex_metric: 0.764483\n"
     ]
    }
   ],
   "source": [
    "# Imports and Constants\n",
    "import os,random \n",
    "import tqdm \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pathlib\n",
    "import tqdm\n",
    "import lightgbm as lgb\n",
    "import torch, gc \n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "class CFG:\n",
    "  seed = 42\n",
    "  TRAIN = True \n",
    "  INFER = True\n",
    "  n_folds = 5\n",
    "  target ='target'\n",
    "  DEBUG= False \n",
    "  ADD_CAT = True\n",
    "  ADD_LAG = True \n",
    "  ADD_DIFF =  [1, 2]\n",
    "  ADD_MIDDLE = True\n",
    "  INPUT = \"./\"\n",
    "  model_dir = \"./\"\n",
    "  sub_dir = \"./\"\n",
    "\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)    \n",
    "\n",
    "\n",
    "def get_not_used():  \n",
    "  return ['row_id', 'customer_ID', 'target', 'cid', 'S_2','D_103','D_139']    \n",
    "\n",
    "# ====================================================\n",
    "#   数据加载\n",
    "# ====================================================\n",
    "if CFG.TRAIN:\n",
    "  fe = f\"{CFG.INPUT}/train_fe_v1.pickle\"\n",
    "  if os.path.exists(fe):\n",
    "    train = pd.read_pickle(fe) \n",
    "  print(train.shape)\n",
    "  train.head()\n",
    "\n",
    "if CFG.DEBUG:\n",
    "  train = train.sample(n=2000, random_state=42).reset_index(drop=True)\n",
    "  features = [col for col in train.columns if col not in  get_not_used()]\n",
    "  \n",
    "if CFG.INFER:\n",
    "    fe = f\"{CFG.INPUT}/test_fe_v1.pickle\"\n",
    "    if os.path.exists(fe):\n",
    "      test = pd.read_pickle(fe) \n",
    "    print(test.shape)\n",
    "    test.head()\n",
    "_ = gc.collect()\n",
    "\n",
    "def do_miss_nan(df):\n",
    "    # Impute missing values\n",
    "    df.fillna(value=-1, inplace=True)\n",
    "    # Replace inf with zeros \n",
    "    df.replace([np.inf, -np.inf], -1, inplace=True)\n",
    "    # Reduce memory\n",
    "    for c in df.columns:\n",
    "      if c in get_not_used(): continue\n",
    "      if str( df[c].dtype )=='int64':\n",
    "          df[c] = df[c].astype('int32')\n",
    "      if str(df[c].dtype )=='float64':\n",
    "          df[c] = df[c].astype('float32')\n",
    "    return df\n",
    "\n",
    "train = do_miss_nan(train)\n",
    "test = do_miss_nan(test)\n",
    "\n",
    "# ====================================================\n",
    "# 模型构建\n",
    "# ====================================================\n",
    "\n",
    "# ### LGBM Params and utility functions\n",
    "class SaveModelCallback:\n",
    "    def __init__(self,\n",
    "                 models_folder: pathlib.Path,\n",
    "                 fold_id: int,\n",
    "                 min_score_to_save: float,\n",
    "                 every_k: int,\n",
    "                 order: int = 0):\n",
    "        self.min_score_to_save: float = min_score_to_save\n",
    "        self.every_k: int = every_k\n",
    "        self.current_score = min_score_to_save\n",
    "        self.order: int = order\n",
    "        self.models_folder: pathlib.Path = models_folder\n",
    "        self.fold_id: int = fold_id\n",
    "\n",
    "    def __call__(self, env):\n",
    "        iteration = env.iteration\n",
    "        score = env.evaluation_result_list[3][2]\n",
    "        if iteration % self.every_k == 0:\n",
    "            #print(f'iteration {iteration}, score={score:.05f}')\n",
    "            if score > self.current_score:\n",
    "                self.current_score = score \n",
    "                print(f'High Score: iteration {iteration}, score={score:.05f}')\n",
    "                joblib.dump(env.model,  f'{CFG.model_dir}/lgbm_fold{self.fold_id}_seed{CFG.seed}_{score:.05f}.pkl')\n",
    "\n",
    "\n",
    "def save_model(models_folder: pathlib.Path, fold_id: int, min_score_to_save: float = 0.793, every_k: int = 50):\n",
    "    return SaveModelCallback(models_folder=models_folder, fold_id=fold_id, min_score_to_save=min_score_to_save, every_k=every_k)\n",
    "\n",
    "params = {\n",
    "          'objective': 'binary',\n",
    "          'metric': \"binary_logloss\",\n",
    "          'boosting': 'dart',\n",
    "          'seed': CFG.seed,\n",
    "          'num_leaves': 100,\n",
    "          'learning_rate': 0.0075,  \n",
    "          'feature_fraction': 0.20,\n",
    "          'bagging_freq': 10,\n",
    "          'bagging_fraction': 0.50,\n",
    "          'n_jobs': -1,\n",
    "          'lambda_l2': 2,\n",
    "          'min_data_in_leaf': 40,\n",
    "          #\"histogram_pool_size\":  10240\n",
    "}\n",
    "def lgbm_train(x, y, xt, yt,fold,\n",
    "               cat_features=['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120',\n",
    "                'D_126', 'D_63', 'D_64', 'D_66', 'D_68']):\n",
    "    print(\"Start training\")  \n",
    "\n",
    "    lgb_train = lgb.Dataset(x, y,feature_name =[col for col in x.columns], categorical_feature = cat_features)\n",
    "    lgb_valid = lgb.Dataset(xt, yt,feature_name =[col for col in x.columns], categorical_feature = cat_features)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        num_boost_round = 11500,\n",
    "        early_stopping_rounds = 100,\n",
    "        verbose_eval = 50,\n",
    "        valid_sets = [lgb_train, lgb_valid],  \n",
    "        feval = lgb_amex_metric,\n",
    "        callbacks=[save_model(models_folder=CFG.INPUT, fold_id=fold, min_score_to_save=0.7931, every_k=50)]\n",
    "        )\n",
    "    return model.predict(xt),model,1\n",
    "\n",
    "\n",
    "# #### Metrics\n",
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "# we still need the official metric since the faster version above is slightly off\n",
    "def amex_metric(y_true, y_pred):\n",
    "    labels = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz = cum_pos_found / total_pos\n",
    "        gini[i] = np.sum((lorentz - weight_random) * weight)\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)\n",
    "\n",
    "def lgb_amex_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'amex_metric', amex_metric(y_true, y_pred), True\n",
    "\n",
    "  \n",
    "# ====================================================\n",
    "# Train LightGBM\n",
    "# ====================================================\n",
    "msgs = {}\n",
    "score = 0\n",
    "not_used = get_not_used()\n",
    "kfold = StratifiedKFold(n_splits = CFG.n_folds, shuffle = True, random_state = CFG.seed) \n",
    "\n",
    "if CFG.TRAIN: \n",
    "  # print(f\"Number of features {len(features)}\")\n",
    "  oof_predictions = np.zeros(len(train))\n",
    "  feature_importances = pd.DataFrame()\n",
    "  not_used = [i for i in not_used if i in train.columns]  \n",
    "  features = [col for col in test.columns if col not in  get_not_used()]       \n",
    "  for fold, (trn_ind, val_ind) in enumerate(kfold.split(train[[CFG.target,\"S_2\",\"customer_ID\"]], train[CFG.target])):  \n",
    "      _ = gc.collect()\n",
    "      x, y = train[features].iloc[trn_ind], train[CFG.target].iloc[trn_ind]\n",
    "      xt, yt= train[features].iloc[val_ind], train[CFG.target].iloc[val_ind]\n",
    "      _ = gc.collect()      \n",
    "\n",
    "      val_pred,model, bst = lgbm_train(x, y, xt, yt,fold)\n",
    "      if fold == 0:\n",
    "        feature_importances[\"feature\"] = model.feature_name()\n",
    "      feature_importances[f\"importance_fold{fold}+1\"] = model.feature_importance()        \n",
    "      joblib.dump(model, f'{CFG.model_dir}/lgbm_fold{fold}_seed{CFG.seed}.pkl')\n",
    "      amex_score = amex_metric(yt.values,val_pred) \n",
    "      msg = f\"Fold {fold} amex {amex_score:.5f}\"   \n",
    "      oof_predictions[val_ind] = val_pred\n",
    "      print(msg)\n",
    "      score += amex_score   \n",
    "      del x,y,xt,yt; gc.collect()\n",
    "    \n",
    "  oof_df = pd.DataFrame({'customer_ID': train['customer_ID'], 'target': train[CFG.target], 'prediction': oof_predictions})\n",
    "  oof_df.to_csv(f'lgbm_{CFG.n_folds}fold_seed{CFG.seed}.csv', index = False)\n",
    "  score /= CFG.n_folds\n",
    "  print(f\"Average amex score: {score:.5f}\")       \n",
    "\n",
    "\n",
    "if CFG.INFER:\n",
    "  test_predictions = np.zeros(len(test))\n",
    "  not_used = [i for i in not_used if i in test.columns]  \n",
    "  for fold in range(CFG.n_folds):\n",
    "    model = joblib.load(f\"{CFG.model_dir}/lgbm_fold{fold}_seed{CFG.seed}.pkl\")\n",
    "    test_pred = model.predict(test[features])\n",
    "    test_predictions += test_pred / CFG.n_folds \n",
    "  test_df = pd.DataFrame({'customer_ID': test['customer_ID'], 'prediction': test_predictions})\n",
    "  test_df.to_csv(f'../sub/test_lgbm_5fold_seed42.csv') \n",
    "\n",
    "print('Infer finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a49471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
